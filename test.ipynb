{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05f85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, core, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "def compose_config_from_path(config_path, config_name=\"config\"):\n",
    "    \"\"\"\n",
    "    Compose a Hydra-compatible configuration from the specified path.\n",
    "    \n",
    "    Args:\n",
    "        config_path (str): Path to the directory containing config files\n",
    "        config_name (str, optional): Name of the main config file (without .yaml extension). \n",
    "                                   Defaults to \"config\".\n",
    "    \n",
    "    Returns:\n",
    "        OmegaConf: Composed configuration object\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the config directory or config file doesn't exist\n",
    "        hydra.errors.HydraException: If there are issues with Hydra configuration\n",
    "    \"\"\"\n",
    "    # Reset Hydra to avoid conflicts\n",
    "    GlobalHydra.instance().clear()\n",
    "    \n",
    "    # Convert to absolute path and validate\n",
    "    config_path = Path(config_path)\n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(f\"Config directory not found: {config_path}\")\n",
    "    \n",
    "    if not config_path.is_dir():\n",
    "        raise ValueError(f\"Config path must be a directory: {config_path}\")\n",
    "    \n",
    "    # Get absolute path and parent directory\n",
    "    abs_config_path = config_path.resolve()\n",
    "    parent_dir = abs_config_path.parent\n",
    "    relative_config_path = abs_config_path.name\n",
    "    \n",
    "    # Save current working directory\n",
    "    original_cwd = os.getcwd()\n",
    "    \n",
    "    try:\n",
    "        # Change to parent directory and use relative path for Hydra\n",
    "        os.chdir(parent_dir)\n",
    "        \n",
    "        # Initialize Hydra with the relative config path\n",
    "        initialize(config_path=relative_config_path, version_base=None)\n",
    "        \n",
    "        # Compose the configuration\n",
    "        cfg = compose(config_name=config_name)\n",
    "        return cfg\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Clean up Hydra instance on error\n",
    "        GlobalHydra.instance().clear()\n",
    "        raise e\n",
    "    finally:\n",
    "        # Always restore original working directory\n",
    "        os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc55e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpotint autoencoder/200000.pth loaded\n",
      "JSON Logger initialized. Logs will be saved to: /mnt/virtual_ai0001071-01239_SR006-nfs1/afedorov/projects/latentdiffusion/checkpoints_one_latent_longrun/logs/latent-diffusion-article-autoencoder-v2.1-longrun/temp_name\n",
      "ðŸ“‚ JSON Logger initialized. Logs will be saved to: /mnt/virtual_ai0001071-01239_SR006-nfs1/afedorov/projects/latentdiffusion/checkpoints_one_latent_longrun/logs\n",
      "ðŸ“‚ Hydra config logged to JSON logger!\n"
     ]
    }
   ],
   "source": [
    "from encoder_trainer import EncoderTrainer\n",
    "os.environ['PROJECT_ROOT'] = '/mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "cfg = compose_config_from_path('./conf')\n",
    "cfg.autoencoder.training.batch_size=128\n",
    "cfg.encoder.latent.num_latents=1\n",
    "cfg.decoder.latent.num_latents=1\n",
    "trainer = EncoderTrainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict\n",
    "\n",
    "trainer.encoder.eval()\n",
    "trainer.decoder.eval()\n",
    "\n",
    "total_loss = torch.Tensor([0.0])\n",
    "valid_dict: Dict[str, torch.Tensor] = dict()\n",
    "valid_count = torch.Tensor([0.0])\n",
    "\n",
    "from dataloader import get_dataloaders\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.autoencoder.model.text_encoder)\n",
    "_, valid_loader = get_dataloaders(cfg, tokenizer, skip_train=False, skip_valid=False, valid_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef34efd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder:\n",
      "  model:\n",
      "    checkpoints_prefix: autoencoder\n",
      "    text_encoder: bert-base-cased\n",
      "    text_encoder_freeze_params: true\n",
      "    num_workers: 10\n",
      "    load_checkpoint: autoencoder/200000.pth\n",
      "  loss:\n",
      "    level_weights:\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "  training:\n",
      "    training_iters: 200000\n",
      "    batch_size: 128\n",
      "    batch_size_per_gpu: 512\n",
      "  params:\n",
      "    text_encoder: 0\n",
      "    encoder: 99275520\n",
      "    decoder: 126266162\n",
      "    total: 225541682\n",
      "  all_params: dict()\n",
      "  logging:\n",
      "    log_freq: 10\n",
      "    eval_freq: 20000\n",
      "    save_freq: 20000\n",
      "  optimizer:\n",
      "    name: stableadam\n",
      "    learning_rate: 0.0002\n",
      "    warmup_lr: 1.0e-08\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 1.0e-05\n",
      "    eps: 1.0e-06\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.98\n",
      "    linear_warmup: 10\n",
      "    grad_clip_norm: 10.0\n",
      "encoder:\n",
      "  attention:\n",
      "    head_size: 64\n",
      "    num_heads: 12\n",
      "    probs_dropout: 0.0\n",
      "    qk_norm: true\n",
      "    implementation: flash_attention_2\n",
      "  embedding:\n",
      "    dim: 768\n",
      "    max_position_embeddings: 128\n",
      "    initializer_range: 0.02\n",
      "  hidden:\n",
      "    size: 768\n",
      "    dropout: 0.1\n",
      "    num_layers: 12\n",
      "    ff_mult: 4\n",
      "  latent:\n",
      "    dim: 768\n",
      "    num_latents: 1\n",
      "  normalization:\n",
      "    layer_eps: 1.0e-05\n",
      "  model:\n",
      "    text_encoder: bert-base-cased\n",
      "    text_encoder_freeze_params: true\n",
      "    mlm_probability: 0.3\n",
      "    bert_masking: true\n",
      "  tokens:\n",
      "    vocab_size: 28996\n",
      "  augmentation:\n",
      "    masking:\n",
      "      encodings_mlm_probability: 0.3\n",
      "      weight: 0.5\n",
      "    gaussian_noise:\n",
      "      delta: 0.7\n",
      "      weight: 0.5\n",
      "    latent_masking:\n",
      "      probability: 0.4\n",
      "      vae_beta: 0.0001\n",
      "      vae_sigma: 1.0\n",
      "decoder:\n",
      "  attention:\n",
      "    head_size: 64\n",
      "    num_heads: 12\n",
      "    probs_dropout: 0.0\n",
      "    qk_norm: true\n",
      "    implementation: flash_attention_2\n",
      "  embedding:\n",
      "    dim: 768\n",
      "    max_position_embeddings: 128\n",
      "    initializer_range: 0.02\n",
      "  hidden:\n",
      "    size: 768\n",
      "    dropout: 0.1\n",
      "    num_layers: 12\n",
      "    ff_mult: 4\n",
      "  latent:\n",
      "    dim: 768\n",
      "    num_latents: 1\n",
      "  normalization:\n",
      "    layer_eps: 1.0e-05\n",
      "  model:\n",
      "    text_encoder: bert-base-cased\n",
      "    text_encoder_freeze_params: true\n",
      "    mlm_probabilities:\n",
      "    - 1.0\n",
      "    bert_masking: true\n",
      "  tokens:\n",
      "    vocab_size: 28996\n",
      "    mask_token_id: 103\n",
      "  finetuning:\n",
      "    is_alpha: false\n",
      "    bert_output_masking: false\n",
      "    latent_masking: false\n",
      "    alpha: 0.8\n",
      "    training_iters: 10000\n",
      "    logging:\n",
      "      log_freq: 1\n",
      "      save_freq: 10000\n",
      "      eval_freq: 1000\n",
      "dataset:\n",
      "  name: wikipedia-emnlp\n",
      "  dataset_path: ${project.path}/data/${.name}\n",
      "  max_sequence_len: 128\n",
      "  swap_cfg_coef: 0.0\n",
      "  metrics:\n",
      "  - mauve\n",
      "  - ppl\n",
      "  - div\n",
      "tokenizer:\n",
      "  add_special_tokens: true\n",
      "  padding: true\n",
      "  truncation: true\n",
      "  return_tensors: pt\n",
      "  return_attention_mask: true\n",
      "  return_token_type_ids: false\n",
      "diffusion:\n",
      "  model:\n",
      "    checkpoints_prefix: diffusion\n",
      "    num_workers: 30\n",
      "    load_checkpoint: true\n",
      "  training:\n",
      "    training_iters: 500000\n",
      "    batch_size: 1024\n",
      "    batch_size_per_gpu: 1024\n",
      "  generation:\n",
      "    num_gen_texts: 3000\n",
      "    texts_dir_path: generated_texts\n",
      "    metrics_dir_path: metrics\n",
      "    num_texts_from_metric: 1000\n",
      "  diffusion:\n",
      "    T: 1.0\n",
      "    eps: 1.0e-05\n",
      "    use_self_cond: true\n",
      "    t_min: 0.05\n",
      "    is_conditional: false\n",
      "  ema:\n",
      "    decay: 0.9999\n",
      "  dynamic:\n",
      "    'N': 200\n",
      "    scheduler: tanh\n",
      "    d: 5\n",
      "    solver: euler\n",
      "    ode_sampling: false\n",
      "  params:\n",
      "    score_estimator: 0\n",
      "  all_params: dict()\n",
      "  logging:\n",
      "    log_freq: 10\n",
      "    eval_freq: 100000\n",
      "    save_freq: 100000\n",
      "  architecture:\n",
      "    unconditional_encoder:\n",
      "      hidden_size: 768\n",
      "      intermediate_size: 3072\n",
      "      num_hidden_layers: 12\n",
      "      num_attention_heads: 12\n",
      "      attention_head_size: 64\n",
      "      attention_probs_dropout_prob: 0.0\n",
      "      layer_norm_eps: 1.0e-05\n",
      "      rope_theta: 10000.0\n",
      "      max_position_embeddings: 512\n",
      "      embedding_dim: 768\n",
      "    time_embedding:\n",
      "      max_period: 10\n",
      "    conditional_encoder:\n",
      "      hidden_size: 768\n",
      "      num_hidden_layers: 12\n",
      "      num_attention_heads: 12\n",
      "      max_position_embeddings: 512\n",
      "  optimizer:\n",
      "    name: adamw\n",
      "    learning_rate: 0.0002\n",
      "    warmup_lr: 1.0e-08\n",
      "    min_lr: 0.0002\n",
      "    weight_decay: 1.0e-05\n",
      "    eps: 1.0e-06\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.98\n",
      "    linear_warmup: 1000\n",
      "    grad_clip_norm: 1.0\n",
      "project:\n",
      "  path: ${oc.env:PROJECT_ROOT}\n",
      "  seed: 0\n",
      "  output_dir: ${project.path}/outputs/\n",
      "  checkpoint_dir: /mnt/virtual_ai0001071-01239_SR006-nfs1/afedorov/projects/latentdiffusion/checkpoints_one_latent_longrun/\n",
      "  run_name: temp_name\n",
      "  name: latent-diffusion-article-autoencoder-v2.1-longrun\n",
      "ddp:\n",
      "  enabled: false\n",
      "  local_rank: ${oc.env:LOCAL_RANK,0}\n",
      "  global_rank: ${oc.env:RANK,0}\n",
      "  world_size: ${oc.env:WORLD_SIZE,1}\n",
      "s3:\n",
      "  bucket: cosmos-latent-diffusion\n",
      "  region: eu-north-1\n",
      "training: autoencoder\n",
      "suffix: v2.0\n",
      "loader:\n",
      "  batch_size: 128\n",
      "  num_workers: 4\n",
      "  pin_memory: true\n",
      "  streaming: false\n",
      "  persistent_workers: true\n",
      "  eval_batch_size: 256\n",
      "model:\n",
      "  length: 128\n",
      "  gradient_accumulation_steps: 2\n",
      "training_setup:\n",
      "  training_iters: 200000\n",
      "data:\n",
      "  train: openwebtext-train\n",
      "  valid: openwebtext-valid\n",
      "  tokenizer_name_or_path: gpt2\n",
      "  cache_dir: /mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion/cache\n",
      "  wrap: false\n",
      "  streaming: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45714d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:35<00:00, 11.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_loader):\n",
    "        batch_size = batch[\"input_ids\"].shape[0]\n",
    "        batch_loss, loss_dict = trainer.calc_loss(batch)\n",
    "        \n",
    "        for k in loss_dict:\n",
    "            if k in valid_dict:\n",
    "                valid_dict[k] += loss_dict[k] * batch_size\n",
    "            else:\n",
    "                valid_dict[k] = torch.Tensor([loss_dict[k] * batch_size])\n",
    "        valid_count += batch_size\n",
    "\n",
    "        total_loss += batch_loss.item() * batch_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409e8449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ce_loss': 0.6875,\n",
       " 'mse_loss': 0.048601116985082626,\n",
       " 'accuracy': 0.828320324420929,\n",
       " 'variation_loss': 0.20029935240745544}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7eb7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8228])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dict['accuracy'] / valid_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
