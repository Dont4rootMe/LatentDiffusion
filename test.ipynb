{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05f85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, core, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "def compose_config_from_path(config_path, config_name=\"config\"):\n",
    "    \"\"\"\n",
    "    Compose a Hydra-compatible configuration from the specified path.\n",
    "    \n",
    "    Args:\n",
    "        config_path (str): Path to the directory containing config files\n",
    "        config_name (str, optional): Name of the main config file (without .yaml extension). \n",
    "                                   Defaults to \"config\".\n",
    "    \n",
    "    Returns:\n",
    "        OmegaConf: Composed configuration object\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the config directory or config file doesn't exist\n",
    "        hydra.errors.HydraException: If there are issues with Hydra configuration\n",
    "    \"\"\"\n",
    "    # Reset Hydra to avoid conflicts\n",
    "    GlobalHydra.instance().clear()\n",
    "    \n",
    "    # Convert to absolute path and validate\n",
    "    config_path = Path(config_path)\n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(f\"Config directory not found: {config_path}\")\n",
    "    \n",
    "    if not config_path.is_dir():\n",
    "        raise ValueError(f\"Config path must be a directory: {config_path}\")\n",
    "    \n",
    "    # Get absolute path and parent directory\n",
    "    abs_config_path = config_path.resolve()\n",
    "    parent_dir = abs_config_path.parent\n",
    "    relative_config_path = abs_config_path.name\n",
    "    \n",
    "    # Save current working directory\n",
    "    original_cwd = os.getcwd()\n",
    "    \n",
    "    try:\n",
    "        # Change to parent directory and use relative path for Hydra\n",
    "        os.chdir(parent_dir)\n",
    "        \n",
    "        # Initialize Hydra with the relative config path\n",
    "        initialize(config_path=relative_config_path, version_base=None)\n",
    "        \n",
    "        # Compose the configuration\n",
    "        cfg = compose(config_name=config_name)\n",
    "        return cfg\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Clean up Hydra instance on error\n",
    "        GlobalHydra.instance().clear()\n",
    "        raise e\n",
    "    finally:\n",
    "        # Always restore original working directory\n",
    "        os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc55e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer: bert-base-cased - BertTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading text encoder: bert-base-cased\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m cfg\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mlatent\u001b[38;5;241m.\u001b[39mnum_latents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m cfg\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mlatent\u001b[38;5;241m.\u001b[39mnum_latents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mEncoderTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion/encoder_trainer.py:113\u001b[0m, in \u001b[0;36mEncoderTrainer.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautoencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# Initialize JSON logger only on main process\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mis_main_process:\n\u001b[0;32m--> 113\u001b[0m         \u001b[43minit_json_logger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m         config_to_wandb(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_loaded \u001b[38;5;129;01mand\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mis_initialized() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mddp\u001b[38;5;241m.\u001b[39menabled:\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion/utils/logging_utils.py:66\u001b[0m, in \u001b[0;36minit_json_logger\u001b[0;34m(cfg, experiment_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Initialize the logger\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m logger \u001b[38;5;241m=\u001b[39m \u001b[43mwandb_json_logger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOmegaConf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“‚ JSON Logger initialized. Logs will be saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logger\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion/utils/wandb_json_logger.py:331\u001b[0m, in \u001b[0;36minit\u001b[0;34m(project, config, save_dir, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the global logger (mimics wandb.init).\"\"\"\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _global_logger\n\u001b[0;32m--> 331\u001b[0m _global_logger \u001b[38;5;241m=\u001b[39m \u001b[43mWandbJSONLogger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _global_logger\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion/utils/wandb_json_logger.py:57\u001b[0m, in \u001b[0;36mWandbJSONLogger.__init__\u001b[0;34m(self, project_name, config, save_dir, experiment_name, update_freq, max_metrics_in_memory)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_plotting \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mEvent()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Initialize plots\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_plot_thread()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Log initial config if provided\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion/utils/wandb_json_logger.py:73\u001b[0m, in \u001b[0;36mWandbJSONLogger._setup_plots\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Metrics - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtight_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/pyplot.py:2801\u001b[0m, in \u001b[0;36mtight_layout\u001b[0;34m(pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39mtight_layout)\n\u001b[1;32m   2794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtight_layout\u001b[39m(\n\u001b[1;32m   2795\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2799\u001b[0m     rect: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2800\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2801\u001b[0m     \u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtight_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrect\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/figure.py:3545\u001b[0m, in \u001b[0;36mFigure.tight_layout\u001b[0;34m(self, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m   3543\u001b[0m previous_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_layout_engine()\n\u001b[1;32m   3544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_layout_engine(engine)\n\u001b[0;32m-> 3545\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3547\u001b[0m     previous_engine, (TightLayoutEngine, PlaceHolderLayoutEngine)\n\u001b[1;32m   3548\u001b[0m ):\n\u001b[1;32m   3549\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_external(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe figure layout has changed to tight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/layout_engine.py:183\u001b[0m, in \u001b[0;36mTightLayoutEngine.execute\u001b[0;34m(self, fig)\u001b[0m\n\u001b[1;32m    181\u001b[0m renderer \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[0;32m--> 183\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mget_tight_layout_figure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_subplotspec_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh_pad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw_pad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    188\u001b[0m     fig\u001b[38;5;241m.\u001b[39msubplots_adjust(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/_tight_layout.py:266\u001b[0m, in \u001b[0;36mget_tight_layout_figure\u001b[0;34m(fig, axes_list, subplotspec_list, renderer, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[1;32m    262\u001b[0m     span_pairs\u001b[38;5;241m.\u001b[39mappend((\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mslice\u001b[39m(ss\u001b[38;5;241m.\u001b[39mrowspan\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m*\u001b[39m div_row, ss\u001b[38;5;241m.\u001b[39mrowspan\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m*\u001b[39m div_row),\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28mslice\u001b[39m(ss\u001b[38;5;241m.\u001b[39mcolspan\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m*\u001b[39m div_col, ss\u001b[38;5;241m.\u001b[39mcolspan\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m*\u001b[39m div_col)))\n\u001b[0;32m--> 266\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[43m_auto_adjust_subplotpars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_nrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ncols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mspan_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43msubplot_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43max_bbox_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max_bbox_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_pad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# kwargs can be none if tight_layout fails...\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# if rect is given, the whole subplots area (including\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# labels) will fit into the rect instead of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# auto_adjust_subplotpars twice, where the second run\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# with adjusted rect parameters.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/_tight_layout.py:82\u001b[0m, in \u001b[0;36m_auto_adjust_subplotpars\u001b[0;34m(fig, renderer, shape, span_pairs, subplot_list, ax_bbox_list, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m subplots:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[0;32m---> 82\u001b[0m         bb \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mmartist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tightbbox_for_layout_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     84\u001b[0m tight_bbox_raw \u001b[38;5;241m=\u001b[39m Bbox\u001b[38;5;241m.\u001b[39munion(bb)\n\u001b[1;32m     85\u001b[0m tight_bbox \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39mtransFigure\u001b[38;5;241m.\u001b[39minverted()\u001b[38;5;241m.\u001b[39mtransform_bbox(tight_bbox_raw)\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/artist.py:1410\u001b[0m, in \u001b[0;36m_get_tightbbox_for_layout_only\u001b[0;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;124;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;124;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[1;32m   1407\u001b[0m \u001b[38;5;124;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfor_layout_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_tightbbox(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:457\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    452\u001b[0m     warn_deprecated(\n\u001b[1;32m    453\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    456\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/axes/_base.py:4499\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[1;32m   4496\u001b[0m     bbox_artists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_bbox_extra_artists()\n\u001b[1;32m   4498\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m bbox_artists:\n\u001b[0;32m-> 4499\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4501\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m bbox\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m   4502\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m bbox\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39minf):\n\u001b[1;32m   4503\u001b[0m         bb\u001b[38;5;241m.\u001b[39mappend(bbox)\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/artist.py:365\u001b[0m, in \u001b[0;36mArtist.get_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_tightbbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    Like `.Artist.get_window_extent`, but includes any clipping.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m        Returns None if clipping results in no intersection.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_on():\n\u001b[1;32m    367\u001b[0m         clip_box \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_box()\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/spines.py:158\u001b[0m, in \u001b[0;36mSpine.get_window_extent\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bb\n\u001b[1;32m    157\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m [bb]\n\u001b[0;32m--> 158\u001b[0m drawn_ticks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m major_tick \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m({\u001b[38;5;241m*\u001b[39mdrawn_ticks} \u001b[38;5;241m&\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\u001b[38;5;241m.\u001b[39mmajorTicks}), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    161\u001b[0m minor_tick \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m({\u001b[38;5;241m*\u001b[39mdrawn_ticks} \u001b[38;5;241m&\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\u001b[38;5;241m.\u001b[39mminorTicks}), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/axis.py:1304\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1302\u001b[0m major_ticks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_major_ticks(\u001b[38;5;28mlen\u001b[39m(major_locs))\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick, loc, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(major_ticks, major_locs, major_labels):\n\u001b[0;32m-> 1304\u001b[0m     \u001b[43mtick\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m     tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mset_text(label)\n\u001b[1;32m   1306\u001b[0m     tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mset_text(label)\n",
      "File \u001b[0;32m/mnt/virtual_ai0001071-01239_SR006-nfs2/micromamba/envs/af_pi0_v2/lib/python3.9/site-packages/matplotlib/axis.py:435\u001b[0m, in \u001b[0;36mXTick.update_position\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate_position\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc):\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set the location of tick in data coords with scalar *loc*.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick1line\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_xdata\u001b[49m((loc,))\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick2line\u001b[38;5;241m.\u001b[39mset_xdata((loc,))\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgridline\u001b[38;5;241m.\u001b[39mset_xdata((loc,))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from encoder_trainer import EncoderTrainer\n",
    "os.environ['PROJECT_ROOT'] = '/mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "cfg = compose_config_from_path('./conf')\n",
    "cfg.autoencoder.training.batch_size=128\n",
    "cfg.encoder.latent.num_latents=1\n",
    "cfg.decoder.latent.num_latents=1\n",
    "trainer = EncoderTrainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict\n",
    "\n",
    "trainer.encoder.eval()\n",
    "trainer.decoder.eval()\n",
    "\n",
    "total_loss = torch.Tensor([0.0])\n",
    "valid_dict: Dict[str, torch.Tensor] = dict()\n",
    "valid_count = torch.Tensor([0.0])\n",
    "\n",
    "from dataloader import get_dataloaders\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.autoencoder.model.text_encoder)\n",
    "_, valid_loader = get_dataloaders(cfg, tokenizer, skip_train=False, skip_valid=False, valid_seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef34efd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder:\n",
      "  model:\n",
      "    checkpoints_prefix: autoencoder\n",
      "    text_encoder: bert-base-cased\n",
      "    text_encoder_freeze_params: true\n",
      "    num_workers: 10\n",
      "    load_checkpoint: autoencoder/200000.pth\n",
      "  loss:\n",
      "    level_weights:\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "  training:\n",
      "    training_iters: 200000\n",
      "    batch_size: 128\n",
      "    batch_size_per_gpu: 512\n",
      "  params:\n",
      "    text_encoder: 0\n",
      "    encoder: 99275520\n",
      "    decoder: 126266162\n",
      "    total: 225541682\n",
      "  all_params: dict()\n",
      "  logging:\n",
      "    log_freq: 10\n",
      "    eval_freq: 20000\n",
      "    save_freq: 20000\n",
      "  optimizer:\n",
      "    name: stableadam\n",
      "    learning_rate: 0.0002\n",
      "    warmup_lr: 1.0e-08\n",
      "    min_lr: 0.0001\n",
      "    weight_decay: 1.0e-05\n",
      "    eps: 1.0e-06\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.98\n",
      "    linear_warmup: 10\n",
      "    grad_clip_norm: 10.0\n",
      "encoder:\n",
      "  attention:\n",
      "    head_size: 64\n",
      "    num_heads: 12\n",
      "    probs_dropout: 0.0\n",
      "    qk_norm: true\n",
      "    implementation: flash_attention_2\n",
      "  embedding:\n",
      "    dim: 768\n",
      "    max_position_embeddings: 128\n",
      "    initializer_range: 0.02\n",
      "  hidden:\n",
      "    size: 768\n",
      "    dropout: 0.1\n",
      "    num_layers: 12\n",
      "    ff_mult: 4\n",
      "  latent:\n",
      "    dim: 768\n",
      "    num_latents: 1\n",
      "  normalization:\n",
      "    layer_eps: 1.0e-05\n",
      "  model:\n",
      "    text_encoder: bert-base-cased\n",
      "    text_encoder_freeze_params: true\n",
      "    mlm_probability: 0.3\n",
      "    bert_masking: true\n",
      "  tokens:\n",
      "    vocab_size: 28996\n",
      "  augmentation:\n",
      "    masking:\n",
      "      encodings_mlm_probability: 0.3\n",
      "      weight: 0.5\n",
      "    gaussian_noise:\n",
      "      delta: 0.7\n",
      "      weight: 0.5\n",
      "    latent_masking:\n",
      "      probability: 0.4\n",
      "      vae_beta: 0.0001\n",
      "      vae_sigma: 1.0\n",
      "decoder:\n",
      "  attention:\n",
      "    head_size: 64\n",
      "    num_heads: 12\n",
      "    probs_dropout: 0.0\n",
      "    qk_norm: true\n",
      "    implementation: flash_attention_2\n",
      "  embedding:\n",
      "    dim: 768\n",
      "    max_position_embeddings: 128\n",
      "    initializer_range: 0.02\n",
      "  hidden:\n",
      "    size: 768\n",
      "    dropout: 0.1\n",
      "    num_layers: 12\n",
      "    ff_mult: 4\n",
      "  latent:\n",
      "    dim: 768\n",
      "    num_latents: 1\n",
      "  normalization:\n",
      "    layer_eps: 1.0e-05\n",
      "  model:\n",
      "    text_encoder: bert-base-cased\n",
      "    text_encoder_freeze_params: true\n",
      "    mlm_probabilities:\n",
      "    - 1.0\n",
      "    bert_masking: true\n",
      "  tokens:\n",
      "    vocab_size: 28996\n",
      "    mask_token_id: 103\n",
      "  finetuning:\n",
      "    is_alpha: false\n",
      "    bert_output_masking: false\n",
      "    latent_masking: false\n",
      "    alpha: 0.8\n",
      "    training_iters: 10000\n",
      "    logging:\n",
      "      log_freq: 1\n",
      "      save_freq: 10000\n",
      "      eval_freq: 1000\n",
      "dataset:\n",
      "  name: wikipedia-emnlp\n",
      "  dataset_path: ${project.path}/data/${.name}\n",
      "  max_sequence_len: 128\n",
      "  swap_cfg_coef: 0.0\n",
      "  metrics:\n",
      "  - mauve\n",
      "  - ppl\n",
      "  - div\n",
      "tokenizer:\n",
      "  add_special_tokens: true\n",
      "  padding: true\n",
      "  truncation: true\n",
      "  return_tensors: pt\n",
      "  return_attention_mask: true\n",
      "  return_token_type_ids: false\n",
      "diffusion:\n",
      "  model:\n",
      "    checkpoints_prefix: diffusion\n",
      "    num_workers: 30\n",
      "    load_checkpoint: true\n",
      "  training:\n",
      "    training_iters: 500000\n",
      "    batch_size: 1024\n",
      "    batch_size_per_gpu: 1024\n",
      "  generation:\n",
      "    num_gen_texts: 3000\n",
      "    texts_dir_path: generated_texts\n",
      "    metrics_dir_path: metrics\n",
      "    num_texts_from_metric: 1000\n",
      "  diffusion:\n",
      "    T: 1.0\n",
      "    eps: 1.0e-05\n",
      "    use_self_cond: true\n",
      "    t_min: 0.05\n",
      "    is_conditional: false\n",
      "  ema:\n",
      "    decay: 0.9999\n",
      "  dynamic:\n",
      "    'N': 200\n",
      "    scheduler: tanh\n",
      "    d: 5\n",
      "    solver: euler\n",
      "    ode_sampling: false\n",
      "  params:\n",
      "    score_estimator: 0\n",
      "  all_params: dict()\n",
      "  logging:\n",
      "    log_freq: 10\n",
      "    eval_freq: 100000\n",
      "    save_freq: 100000\n",
      "  architecture:\n",
      "    unconditional_encoder:\n",
      "      hidden_size: 768\n",
      "      intermediate_size: 3072\n",
      "      num_hidden_layers: 12\n",
      "      num_attention_heads: 12\n",
      "      attention_head_size: 64\n",
      "      attention_probs_dropout_prob: 0.0\n",
      "      layer_norm_eps: 1.0e-05\n",
      "      rope_theta: 10000.0\n",
      "      max_position_embeddings: 512\n",
      "      embedding_dim: 768\n",
      "    time_embedding:\n",
      "      max_period: 10\n",
      "    conditional_encoder:\n",
      "      hidden_size: 768\n",
      "      num_hidden_layers: 12\n",
      "      num_attention_heads: 12\n",
      "      max_position_embeddings: 512\n",
      "  optimizer:\n",
      "    name: adamw\n",
      "    learning_rate: 0.0002\n",
      "    warmup_lr: 1.0e-08\n",
      "    min_lr: 0.0002\n",
      "    weight_decay: 1.0e-05\n",
      "    eps: 1.0e-06\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.98\n",
      "    linear_warmup: 1000\n",
      "    grad_clip_norm: 1.0\n",
      "project:\n",
      "  path: ${oc.env:PROJECT_ROOT}\n",
      "  seed: 0\n",
      "  output_dir: ${project.path}/outputs/\n",
      "  checkpoint_dir: /mnt/virtual_ai0001071-01239_SR006-nfs1/afedorov/projects/latentdiffusion/checkpoints_one_latent_longrun/\n",
      "  run_name: temp_name\n",
      "  name: latent-diffusion-article-autoencoder-v2.1-longrun\n",
      "ddp:\n",
      "  enabled: false\n",
      "  local_rank: ${oc.env:LOCAL_RANK,0}\n",
      "  global_rank: ${oc.env:RANK,0}\n",
      "  world_size: ${oc.env:WORLD_SIZE,1}\n",
      "s3:\n",
      "  bucket: cosmos-latent-diffusion\n",
      "  region: eu-north-1\n",
      "training: autoencoder\n",
      "suffix: v2.0\n",
      "loader:\n",
      "  batch_size: 128\n",
      "  num_workers: 4\n",
      "  pin_memory: true\n",
      "  streaming: false\n",
      "  persistent_workers: true\n",
      "  eval_batch_size: 256\n",
      "model:\n",
      "  length: 128\n",
      "  gradient_accumulation_steps: 2\n",
      "training_setup:\n",
      "  training_iters: 200000\n",
      "data:\n",
      "  train: openwebtext-train\n",
      "  valid: openwebtext-valid\n",
      "  tokenizer_name_or_path: gpt2\n",
      "  cache_dir: /mnt/virtual_ai0001071-01239_SR006-nfs2/afedorov/projects/LatentDiffusion/cache\n",
      "  wrap: false\n",
      "  streaming: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45714d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:35<00:00, 11.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_loader):\n",
    "        batch_size = batch[\"input_ids\"].shape[0]\n",
    "        batch_loss, loss_dict = trainer.calc_loss(batch)\n",
    "        \n",
    "        for k in loss_dict:\n",
    "            if k in valid_dict:\n",
    "                valid_dict[k] += loss_dict[k] * batch_size\n",
    "            else:\n",
    "                valid_dict[k] = torch.Tensor([loss_dict[k] * batch_size])\n",
    "        valid_count += batch_size\n",
    "\n",
    "        total_loss += batch_loss.item() * batch_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409e8449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ce_loss': 0.6875,\n",
       " 'mse_loss': 0.048601116985082626,\n",
       " 'accuracy': 0.828320324420929,\n",
       " 'variation_loss': 0.20029935240745544}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7eb7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8228])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dict['accuracy'] / valid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e9beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "embedding_matrix = AutoModel.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    add_pooling_layer=False,\n",
    ").embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580ca3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10, 1024]), torch.Size([5, 10, 768]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "l = torch.nn.Linear(768, 1024)\n",
    "t = embedding_matrix(torch.randint(0, 100, (5, 10)))\n",
    "l(t).shape, t.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
